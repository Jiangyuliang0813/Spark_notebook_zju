# 第一章 Spark数据分析导论
## 1.1 Spark是什么
- Spark是一个用来实现快速而通用的集群计算平台。
- Spark可以在内存中进行计算，不过即使必须在磁盘上进行复杂的计算，Spark依然比MapReduce更加高效。
- Spark适用于各种各样原先需要多种不同的分布式平台的场景，通过在统一的框架下支持这些不同的计算，Spark是我们可以简单而低耗的把各种处理流程整合在一起
- Spark提供的接口十分丰富，除了提供基于Python、Java、Scala、SQL的简单易用的API，还能连接hadoop集群上
---
## 1.2 一个大一统的软件栈
### 1.2.1 Spark SQL 
- 处理结构化数据的程序包
- 使用SQL，或者HQL来查询数据
### 1.2.2 Spark Streaming 
- 对实时数据进行流使计算的组件
### 1.2.3 Spark MLlib 
- 提供常见的机器学习功能的程序库
### 1.2.4 Spark GraphX 
- 用来操作图的程序库，可以进行并行的图计算。
### 1.2.5 Spark Core
- 实现了Spark的基本功能，包含任务调度、内存管理、错误恢复、存储系统交互
- 对RDD（**弹性分布式数据集**）进行了API定义
### 1.2.6 集群管理器
- Spark支持在各种集群管理器上运行（cluster manager），包括Hadoop YARN、Apache Mesos,以及Spark自带的一个简易调度器，叫做独立调度器
---
## 1.3 Spark的用户与用途
- 目标：数据科学家与工程师 
- 应用: 数据科学应用与数据处理应用
